ğŸ—ï¸ BIG-DIG-HEAP

BIG-DIG-HEAP is a decentralized web archiving platform that enables users to capture, store, and retrieve high-fidelity snapshots of web content â€” powered by a Python backend and the Qortal decentralized network. Think archive.is meets decentralized storage: a resilient archive of web pages that lives on a peer-to-peer data network rather than centralized servers.

ğŸš€ Overview

BIG-DIG-HEAP lets you:

ğŸ“Œ Submit live web URLs for archiving

ğŸ“¦ Store rendered snapshots (HTML, assets, screenshots, and optional WARC)

ğŸ”— Publish archive manifests on the Qortal Data Network (QDN)

ğŸŒ Retrieve snapshots via a decentralized Q-App frontend

ğŸ“Š Track archive status and metadata through a RESTful API

â€œDig deep into history â€” and keep it safe forever.â€

ğŸ§  Motivation

The modern web is ephemeral. Pages disappear or change without notice, yet many contain content we want preserved. Traditional archival systems are centralized and depend on single entities. BIG-DIG-HEAP moves archiving into a decentralized realm, leveraging Qortalâ€™s blockchain and distributed storage to make archives resilient, censorship-resistant, and verifiable.

ğŸ“¦ Features

â­ High-fidelity snapshots
âœ” Full page HTML
âœ” Screenshots
âœ” Optional WARC (standard archive format)

ğŸ” Decentralized storage
âœ” Manifest hashes on Qortal blockchain
âœ” Content served by QDN

âš™ï¸ Developer-friendly API
âœ” REST endpoints
âœ” Async job queue
âœ” Metadata and retrieval

ğŸ“± Q-App integration
âœ” Simple UI for users
âœ” Native Qortal publishing and retrieval

ğŸ§© Architecture

BIG-DIG-HEAP consists of:

* Crawler Subsystem
  * A Python service (using Playwright) that:
  * Renders dynamic web pages
  * Captures HTML, screenshots, and optionally WARC files
  * Produces archive manifests and asset bundles

* Backend API
  * A FastAPI service that:
    * Accepts archive requests
    * Queues crawl jobs
    * Reports status and metadata

* Orchestrates packaging and publishing

* Qortal Bridge

* A module that:
  * Publishes archive manifests to Qortal
  * Uploads chunks to QDN
  * Records immutable references on the blockchain

* Q-App Frontend
  * A lightweight JavaScript Qortal App that:
    * Lets users submit URLs for archiving
    * Displays status and snapshot history
    * Fetches archived content from decentralized storage

---

ğŸ› ï¸ Getting Started

* Prerequisites
  * Python 3.10+
  * Node.js & NPM
  * Docker (optional)
  * Qortal Core or access to Qortal API

ğŸ› ï¸ Quick Start

  * Clone the repo  
```
git clone https://github.com/8bittengeek/big-dig-heap.git
cd big-dig-heap
```
  * Launch development environment
```
docker compose up --build
```
  * Access services
  
Backend API: `http://localhost:8000`

Q-App UI: `http://localhost:8080`

API docs: `http://localhost:8000/docs`

---

```
ğŸ“ Project Structure
/
â”œâ”€ backend/        # FastAPI REST API
â”œâ”€ crawler/        # Python snapshot & crawler logic
â”œâ”€ qortal/         # Bridge to Qortal publishing
â”œâ”€ qapp/           # Q-App frontend
â”œâ”€ docker-compose.yml
â”œâ”€ README```.md
```

ğŸ§ª Usage Examples
Submit a URL for Archiving
```
curl -X POST http://localhost:8000/archive \
     -H "Content-Type: application/json" \
     -d '{"url":"https://example.com"}'
```
Check Job Status
```
curl http://localhost:8000/archive/<JOB_ID>
```
---

ğŸ§  How It Works

1. User submits a URL via the Q-App or REST API.

2. Backend queues a crawl job.

3. Crawler fetches and renders the page, then packages assets.

4. Archive manifest is generated and hashes computed.

5. Manifest uploaded to QDN; hashes committed to Qortal blockchain.

6. Snapshots can be retrieved via the Q-App or direct fetch from QDN.

---

ğŸ’¡ Contributing

Contributions are welcome! Feel free to:

* Improve crawler fidelity

* Add search or indexing

* Expand Q-App UI features

* Harden job scheduling and retries

---

ğŸ“œ License

This project is released under the MIT License â€” see [LICENSE.md](LICENSE.md) for details.

ğŸª™ Acknowledgements

BIG-DIG-HEAP was inspired by open archival tools and decentralized storage innovations.

---

# TECHNICAL DESIGN NOTES

ğŸ§  Understanding the Key Concepts

1ï¸âƒ£ What Qortal Provides

* Blockchain + Data Network (QDN): Qortalâ€™s QDN lets you store encrypted, chunked data in a peer-to-peer network secured by the blockchain. 
Qortal

* Publishing Websites & Apps: Qortal supports publishing websites and apps (Q-Apps) that are hosted decentralized, fee-less and indefinitely. 
wiki.qortal.org

* Q-Apps API: JavaScript-based apps can interact with users and the blockchain through Qortalâ€™s APIs, making it usable with modern front-ends. 
Qortal

* BIG-DIG-HEAP app will likely be a architecture â€” a crawler running on backend servers to fetch and snapshot web content, plus a Q-App frontend that interacts with Qortal for storage, retrieval, and distribution.

---

ğŸ§© What Web Archiving Usually Involves

Before we plug into decentralized storage, letâ€™s take a quick look at design patterns from existing archiving tools:

ğŸ“Œ Archive Tools & Techniques

* Archive.today / archive.is: Takes snapshots of a pageâ€™s appearance and static content and stores them for retrieval. 
Wikipedia

* Wayback Machine: Crawls and stores periodic snapshots for replay over time. 
Wikipedia

* ArchiveBox: Open-source tool for self-hosted web archiving and retrieval, can store HTML, JS, PDFs, screenshots, WARC files, media, etc. 

These tools mix crawling logic (download, render, process content) with storage formats (HTML, WARC, screenshots) that BIG-DIG-HEAP needs to model or interface with.

---

ğŸ› ï¸ Architecture Outline for BIG-DIG-HEAP

ğŸ§± 1. Crawler & Archival Backend

* Build a service (e.g., in Python, Go, Rust, or Node.js) that:

* Accepts a URL to archive

* Fetches the page (headless browser or HTTP fetch)

* Renders dynamic content (needs a headless browser like Puppeteer/Playwright)

* Extracts content (HTML, CSS, JS, media, images)

* Generates snapshots (HTML screenshot, PDF, WARC)

* Stores metadata (timestamp, hashes, dependencies)

* This is similar in intent to ArchiveBox but tailored to the needs of BIG-DIG-HEAP.

---

ğŸ“¦ 2. Chunking & Storage Module

Because Qortalâ€™s Data Network can store encrypted, chunked data, BIG-DIG-HEAP needs:

* A component to chunk archived data

* Compute content hashes

* Build a manifest describing the archive snapshot

* Publish a hash manifest transaction to Qortal so others can fetch and validate content. 
  
This step bridges archiving logic with Qortalâ€™s decentralized storage layer.

---

ğŸ”— 3. Q-App Frontend

Develop a Q-App (likely JavaScript with a modern UI framework like React or Svelte) that:

* Lets users submit URLs to be archived

* Shows archival status and versions

* Lists archived snapshots with metadata

* Fetches archived content using QDNâ€™s decentralized fetch APIs

The Q-App would interact with BIG-DIG-HEAP backend (crawler) and Qortal to coordinate storage and retrieval.

---

ğŸ›¡ï¸ 4. Security, Integrity & Versioning

* Every archived snapshot should include cryptographic hashes.

* Storing hashes in the blockchain gives immutable proof of content versioning.

* Consider formats like WARC, HTML + resource bundles, and even screenshots for extra fidelity.

* These patterns are widely used in the archival community because they help with verifiability and replay accuracy.

---

ğŸ“ˆ Development Technologies

| Component	| Suggested Stack |
| --------- | --------------- |
| Crawler / Scraper	Puppeteer/Playwright (JS) or Headless Chrome / Chrome DevTools Protocol
| Backend API |	Python (FastAPI), Go, or Rust (Actix/Hyper) |
| Archival Storage Format | WARC, HTML Bundles, PDF, Screenshots |
| Q-App Frontend | JavaScript + React / Svelte, Q-Apps API |
| Deployment | Docker / Kubernetes for crawler service |


---

# High Level System Architecture

Diagram shows the major components and how they inter-connect.

```mermaid
flowchart LR
    subgraph Client
        QApp[Q-App Frontend]
    end

    subgraph API_Server
        API[Backend Python API]
    end

    subgraph CrawlerService
        Crawler[Snapshot + Crawler Worker]
        Packager[Archive Packager]
    end

    subgraph Qortal_Network
        QDN[Qortal Data Network QDN]
        BC[Qortal Blockchain]
    end

    QApp -->|Submit URL| API
    API -->|Queue Job| Crawler
    Crawler --> Packager
    Packager -->|Manifest + Chunks| QDN
    Packager -->|Hash| BC
    QApp -->|Fetch Archive| QDN
    QApp -->|Resolve Metadata| API
```
# Backend Subsystem Breakdown

Diagram focuses on internal components of the Python backend and how they relate.

```mermaid
flowchart TB
    subgraph Backend_API
        API_Router[API Router FastAPI]
        JobQueue[Job Queue]
        DB[Metadata DB]
    end

    subgraph Worker_Pool
        CrawlWorker[Crawl Worker]
        PackWorker[Packager Worker]
    end

    API_Router -->|enqueue| JobQueue
    JobQueue --> CrawlWorker
    CrawlWorker --> DB
    CrawlWorker --> PackWorker
    PackWorker --> DB
```

# Crawler + Archival Subsystem

Diagram detailes flow for generating snapshots

```mermaid
flowchart LR
    UserReq[URL Request]
    Headless[Headless Browser Playwright]
    StaticFetch[HTTP Fetch]
    ProcHTML[Process DOM & Resources]
    Screenshot[Screenshot]
    WARCGen[WARC Generation optional]
    AssetStore[Local Asset Store]
    ManifestGen[Manifest JSON]

    UserReq --> Headless
    Headless --> ProcHTML
    Headless --> Screenshot
    ProcHTML --> StaticFetch
    StaticFetch --> AssetStore
    Screenshot --> AssetStore
    WARCGen --> AssetStore
    AssetStore --> ManifestGen
```

# Qortal Integration Flow

Diagram shows how packaging and QDN interaction works

```mermaid
flowchart TB
    Manifest[Archive Manifest]
    Chunker[Chunk + Encrypt]
    QDN
    Blockchain[Qortal Blockchain]
    Fetcher[Q-App Fetch Module]

    Manifest --> Chunker
    Chunker --> QDN
    Chunker --> Blockchain
    QDN --> Fetcher
    Blockchain --> Fetcher
```

# Q-App Frontend Flow

Diagram outlines user interactions via the decentralized frontend

```mermaid
flowchart LR
    User[User in Browser]
    QAppUI[Q-App UI]
    QortalAPI[QDN Fetch API]
    BackendAPI

    User --> QAppUI
    QAppUI -->|Submit| BackendAPI
    QAppUI -->|Get Archive| QortalAPI
    QAppUI -->|Get Metadata| BackendAPI
```
